# ğŸš€ Multinomial and Binary Logistic Regression From Scratch  

This repository contains a **custom implementation of Multinomial and Binary Logistic Regression**, built entirely from scratch. The purpose is to **gain a deeper understanding of logistic regression**, including probability estimation, cost function minimization, and different optimization techniques such as **Newton's Method** and **Gradient Descent**.

---

## ğŸ“Œ Features & Concepts Covered  
âœ” **Binary and Multinomial Logistic Regression implementation from scratch**, without using Scikit-Learnâ€™s `LogisticRegression`.  
âœ” **Softmax function** for multinomial classification and **Sigmoid function** for binary classification.  
âœ” **Gradient Descent vs. Newton's Method**: Exploring different optimization strategies to estimate model parameters.  
âœ” **Negative Log-Likelihood (NLL) loss function** for model training.  
âœ” **Vectorized implementation** to improve computational efficiency.  
âœ” **Application of models to real-world datasets**:  
  - **Titanic Dataset** for binary classification.  
  - **Wine Quality Dataset** for multinomial classification.
    
âœ” **Comparison with Scikit-Learn's implementation**, ensuring correctness and efficiency.  

---

## ğŸ“‚ Repository Structure  
ğŸ“œ **multinomial_wine_classifier.ipynb**: Jupyter Notebook where a **Multinomial Logistic Regression** model is implemented from scratch to classify wine quality.  
ğŸ“œ **binomial_titanic_classifier.ipynb**: Jupyter Notebook implementing **Binary Logistic Regression**, used to predict survival on the Titanic dataset.  
ğŸ“– **Logistic Regression.pdf**: Theoretical background covering **logistic regression, softmax function, cost function derivation, and optimization techniques**.  
ğŸ“Š **Titanic.csv**: Dataset used for binary classification.  
ğŸ“Š **winequality-white.csv**: Dataset used for multinomial classification.  

---

## ğŸ“˜ Theory Overview (From Logistic Regression.pdf)  
The **Logistic Regression model** is a probabilistic classification model for **binary and multiclass classification**. The document explains:  
- **Why Logistic Regression is needed for classification instead of Linear Regression**.  
- **Sigmoid function vs. Softmax function** for binary vs. multinomial classification.  
- **Negative Log-Likelihood (NLL) as a loss function** and how to minimize it.  
- **Optimization methods**:  
  - **Gradient Descent** (step-based optimization).  
  - **Newtonâ€™s Method** (second-order optimization for faster convergence).  
- **Hessian matrix and how it improves weight estimation in Newtonâ€™s Method**.  

---

## ğŸ† Practical Implementation  

### 1ï¸âƒ£ **Multinomial Logistic Regression (winequality-white.csv)**  
ğŸ“œ **multinomial_wine_classifier.ipynb** covers:  
âœ” Data preprocessing: Handling missing values, feature scaling.  
âœ” Implementing **Softmax function** to model multiple classes.  
âœ” **Custom implementation of Gradient Descent and Newtonâ€™s Method**.  
âœ” Evaluating model accuracy using **Confusion Matrix, Precision, Recall, and F1-score**.  
âœ” **Comparison with Scikit-Learn's Multinomial Logistic Regression**.  

### 2ï¸âƒ£ **Binary Logistic Regression (Titanic Dataset)**  
ğŸ“œ **binomial_titanic_classifier.ipynb** covers:  
âœ” Implementing **Sigmoid function** for binary classification.  
âœ” Computing **Negative Log-Likelihood (NLL) loss function**.  
âœ” Training using **Gradient Descent**.  
âœ” Evaluating the model and comparing with Scikit-Learn.  

---

## ğŸš€ How to Use the Repository  
1ï¸âƒ£ Clone the repository:  
```bash
 git clone https://github.com/antoniocastajr/Logistic-Regression.git
