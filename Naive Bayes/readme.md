# ðŸš€ Naive Bayes   

This repository presents a **custom implementation of the Gaussian Naive Bayes classifier**, built from scratch. The goal is to understand and apply **Bayes' Theorem** in a practical machine learning task, without relying on pre-built classifiers.  

## ðŸ“Œ Features & Concepts Covered  
âœ” Development of **Gaussian Naive Bayes from scratch**, implementing probability calculations manually.  
âœ” Application of **Bayes' Theorem** to classify data points based on probability distributions.  
âœ” Calculation of **mean, variance, and probability density function (PDF)** for Gaussian (Normal) distributions.  
âœ” Comparison of the custom implementation against Scikit-Learnâ€™s **GaussianNB** to validate accuracy.  
âœ” Application of the model on the **Iris dataset**, a well-known classification problem.  

---

## ðŸ“‚ Repository Structure  
ðŸ“œ **iris_classifier.ipynb** â†’ Jupyter Notebook where the custom Gaussian Naive Bayes classifier is implemented, trained, and tested.  
ðŸ“– **Naive Bayes.pdf** â†’ Theoretical background covering **Bayes' Theorem, probability distributions, and different Naive Bayes classifiers**.  
ðŸ“Š **Iris.csv** â†’ Dataset used for training.  

---

## ðŸ“˜ Theory Overview (From Naive Bayes.pdf)  
The **Naive Bayes algorithm** is a probabilistic classification model based on **Bayes' theorem**. The document explains:  
- **Fundamentals of probability**: independent vs. dependent events, mutually exclusive vs. overlapping events.  
- **Probability distributions**: Gaussian (Normal), Binomial, and Multinomial distributions.  
- **Bayesâ€™ Theorem** and how it is used to update probabilities based on new evidence.  
- **Gaussian Naive Bayes**: Assumes continuous features follow a **normal distribution** and calculates class probabilities using the probability density function (PDF).  
- **Comparison between different types of Naive Bayes classifiers**: Gaussian, Multinomial, and Bernoulli.  

This project serves as a deep dive into **probabilistic classification**, demonstrating how Naive Bayes can be implemented from first principles.  
 

